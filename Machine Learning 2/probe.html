<!DOCTYPE html>
<html>
  <head>
    <title>Machine Learning II - Probe Exam</title>
  </head>
  <body>
    <h1>Machine Learning II - Probe Exam</h1>

    <ol>
      <li>
        1. What is the primary difference between unsupervised learning and
        supervised learning in machine learning?
        <ul>
          <li>
            A) Unsupervised learning uses labeled data, while supervised
            learning does not.
          </li>
          <li>
            <b
              >B) Supervised learning uses labeled data, while unsupervised
              learning does not.</b
            >
          </li>
          <li>
            C) Both unsupervised and supervised learning use labeled data.
          </li>
          <li>
            D) Both unsupervised and supervised learning do not use labeled
            data.
          </li>
        </ul>
      </li>

      <li>
        2. In unsupervised learning, what is the goal of cluster analysis?
        <ul>
          <li>A) To classify data points into predefined categories.</li>
          <li>
            <b>B) To identify structures and patterns in unknown data.</b>
          </li>
          <li>C) To train a model to make predictions.</li>
          <li>D) To calculate distances between data points.</li>
        </ul>
      </li>

      <li>
        3. Which algorithm is used for partitioning data points into clusters in
        unsupervised learning?
        <ul>
          <li>A) K-Nearest Neighbor</li>
          <li>B) Support Vector Machines</li>
          <li><b>C) K-Means</b></li>
          <li>D) Artificial Neural Networks</li>
        </ul>
      </li>

      <li>
        4. In the K-Means clustering algorithm, how are cluster centers
        initialized?
        <ul>
          <li><b>A) Randomly</b></li>
          <li>B) By calculating the average of data points</li>
          <li>C) By using the Euclidean distance</li>
          <li>D) By using support vectors</li>
        </ul>
      </li>

      <li>
        5. Which method is used to determine the distance between two clusters
        in hierarchical clustering?
        <ul>
          <li><b>A) Single-Linkage</b></li>
          <li>B) Complete-Linkage</li>
          <li>C) Average-Linkage</li>
          <li>D) All of the above</li>
        </ul>
      </li>

      <li>
        6. What is the purpose of a dendrogram in hierarchical clustering?
        <ul>
          <li>A) To calculate distances between data points.</li>
          <li>
            <b
              >B) To visualize the relationships between data points and
              clusters.</b
            >
          </li>
          <li>C) To initialize cluster centers.</li>
          <li>D) To determine the number of clusters.</li>
        </ul>
      </li>

      <li>
        7. What distance metric can be used to calculate the distance between
        data points in K-Nearest Neighbor (KNN) classification?
        <ul>
          <li><b>A) Euclidean distance</b></li>
          <li>B) Manhattan distance</li>
          <li>C) Maximum distance</li>
          <li>D) All of the above</li>
        </ul>
      </li>

      <li>
        8. In KNN classification, how are new data points assigned to a class?
        <ul>
          <li>A) By random assignment</li>
          <li>
            <b
              >B) By choosing the class with the maximum number of data points
              among the K-nearest neighbors</b
            >
          </li>
          <li>
            C) By choosing the class with the minimum number of data points
            among the K-nearest neighbors
          </li>
          <li>D) By using the Euclidean distance</li>
        </ul>
      </li>

      <li>
        9. When applying K-Means clustering, how do you decide the number of
        clusters (K) in advance?
        <ul>
          <li>A) By selecting it randomly</li>
          <li>B) By using a predefined value</li>
          <li><b>C) By calculating it based on data characteristics</b></li>
          <li>D) By not specifying K in advance</li>
        </ul>
      </li>

      <li>
        10. What is the role of the distance function in K-Means clustering?
        <ul>
          <li>A) To determine the color of clusters.</li>
          <li><b>B) To calculate the distances between data points.</b></li>
          <li>C) To initialize the cluster centers.</li>
          <li>D) To count the number of data points in each cluster.</li>
        </ul>
      </li>

      <li>
        11. Which of the following is NOT a method to determine distances
        between two data points?
        <ul>
          <li><b>A) Euclidean distance</b></li>
          <li>B) Manhattan distance</li>
          <li>C) Maximilian distance</li>
          <li>D) Elevation distance</li>
        </ul>
      </li>

      <li>
        12. In hierarchical clustering, how is the distance between two clusters
        calculated using the single-linkage method?
        <ul>
          <li>
            A) By taking the maximum distance between data points in the two
            clusters.
          </li>
          <li>
            <b
              >B) By taking the minimum distance between data points in the two
              clusters.</b
            >
          </li>
          <li>
            C) By taking the average distance between data points in the two
            clusters.
          </li>
          <li>D) By using the Manhattan distance.</li>
        </ul>
      </li>

      <li>
        13. What is the main objective of K-Nearest Neighbor (KNN)
        classification?
        <ul>
          <li>A) To divide data points into clusters.</li>
          <li><b>B) To make predictions based on labeled data.</b></li>
          <li>C) To visualize data in two dimensions.</li>
          <li>D) To perform dimensionality reduction.</li>
        </ul>
      </li>

      <li>
        14. Which of the following algorithms is used for binary classification
        in supervised learning?
        <ul>
          <li>A) K-Means</li>
          <li>B) Hierarchical clustering</li>
          <li><b>C) Support Vector Machines</b></li>
          <li>D) Average-Linkage</li>
        </ul>
      </li>

      <li>
        15. How is the number of clusters determined in hierarchical clustering?
        <ul>
          <li>A) By randomly selecting a value.</li>
          <li>B) By the number of data points in the dataset.</li>
          <li>
            <b>C) By the specific hierarchical clustering method used.</b>
          </li>
          <li>D) By the machine learning model.</li>
        </ul>
      </li>

      <li>
        16. In the context of unsupervised learning, what is the purpose of the
        K-Means algorithm?
        <ul>
          <li>A) To calculate distances between data points.</li>
          <li><b>B) To find structures and patterns in unknown data.</b></li>
          <li>C) To assign labels to data points.</li>
          <li>D) To determine the number of clusters in advance.</li>
        </ul>
      </li>

      <li>
        17. Which distance metric is used to calculate the distance between data
        points in K-Means clustering?
        <ul>
          <li><b>A) Euclidean distance</b></li>
          <li>B) Manhattan distance</li>
          <li>C) Maximum distance</li>
          <li>D) Average distance</li>
        </ul>
      </li>

      <li>
        18. How is the similarity or distance between two clusters determined in
        hierarchical clustering using the complete-linkage method?
        <ul>
          <li>
            <b
              >A) By taking the maximum distance between data points in the two
              clusters.</b
            >
          </li>
          <li>
            B) By taking the minimum distance between data points in the two
            clusters.
          </li>
          <li>
            C) By taking the average distance between data points in the two
            clusters.
          </li>
          <li>D) By using the Euclidean distance.</li>
        </ul>
      </li>

      <li>
        19. In K-Nearest Neighbor (KNN) classification, what happens when the
        value of K is increased?
        <ul>
          <li>A) The model becomes more sensitive to outliers.</li>
          <li><b>B) The decision boundary becomes more complex.</b></li>
          <li>C) The model becomes more robust to noise.</li>
          <li>
            D) The model becomes less sensitive to the number of neighbors.
          </li>
        </ul>
      </li>

      <li>
        20. What is the primary goal of deep learning with artificial neural
        networks?
        <ul>
          <li>A) To calculate distances between data points.</li>
          <li>
            <b>B) To identify structures and patterns in unknown data.</b>
          </li>
          <li>
            C) To create hierarchical models for feature extraction and data
            representation.
          </li>
          <li>D) To generate labeled data for supervised learning.</li>
        </ul>
      </li>
    </ol>
  </body>
</html>
