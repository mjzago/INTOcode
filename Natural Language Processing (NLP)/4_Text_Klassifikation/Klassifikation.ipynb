{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation \n",
    "\n",
    "In diesem Notebook trainieren wir einen Classifier. Aus Beispielen lernt der Classifier, zu welcher Klasse ein Element gehört, und kann neue Elemente mit den gelernten Regeln einordnen. \n",
    "\n",
    "Wir lesen zunächst Dokumente aus 4 Wikipedia-Kategorien ein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texten sammeln (API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/f1/7d/2e562207176a5dcdad513085670674bb11ffaf37e1393eacb6d7fb502481/scikit_learn-1.3.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\mjzag\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.25.2)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Obtaining dependency information for scipy>=1.5.0 from https://files.pythonhosted.org/packages/06/15/e73734f9170b66c6a84a0bd7e03586e87e77404e2eb8e34749fc49fa43f7/scipy-1.11.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scipy-1.11.2-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
      "     ---------------------------------------- 0.0/59.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 59.1/59.1 kB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\mjzag\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.3.1)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.1-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.6/9.2 MB 12.0 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.6/9.2 MB 12.0 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.8/9.2 MB 5.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.7/9.2 MB 9.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.3/9.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.5/9.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.0/9.2 MB 9.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.5/9.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.0/9.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.5/9.2 MB 9.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.0/9.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.9/9.2 MB 9.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.4/9.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.7/9.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.2/9.2 MB 9.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.6/9.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.1/9.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.6/9.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading scipy-1.11.2-cp311-cp311-win_amd64.whl (44.0 MB)\n",
      "   ---------------------------------------- 0.0/44.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/44.0 MB 13.8 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.9/44.0 MB 11.6 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.4/44.0 MB 11.3 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.8/44.0 MB 10.2 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 2.2/44.0 MB 9.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.6/44.0 MB 9.6 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 3.0/44.0 MB 9.5 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.4/44.0 MB 9.3 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.8/44.0 MB 9.4 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 4.3/44.0 MB 9.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.8/44.0 MB 9.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 5.2/44.0 MB 9.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.6/44.0 MB 9.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.9/44.0 MB 9.2 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.3/44.0 MB 9.2 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.5/44.0 MB 9.0 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.5/44.0 MB 8.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 6.9/44.0 MB 8.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.2/44.0 MB 8.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.7/44.0 MB 8.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.0/44.0 MB 8.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.5/44.0 MB 8.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 8.9/44.0 MB 8.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 9.4/44.0 MB 8.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 9.9/44.0 MB 8.5 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 10.4/44.0 MB 8.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.9/44.0 MB 8.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 11.4/44.0 MB 8.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 11.9/44.0 MB 8.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 12.4/44.0 MB 8.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 12.9/44.0 MB 8.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 13.4/44.0 MB 9.0 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 13.9/44.0 MB 9.0 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 14.3/44.0 MB 9.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 14.7/44.0 MB 9.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 15.2/44.0 MB 8.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 15.6/44.0 MB 8.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 16.0/44.0 MB 9.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 16.5/44.0 MB 9.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 16.9/44.0 MB 9.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.4/44.0 MB 9.8 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 17.8/44.0 MB 9.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.2/44.0 MB 9.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.7/44.0 MB 9.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.1/44.0 MB 9.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.5/44.0 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 19.9/44.0 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 20.4/44.0 MB 9.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 20.8/44.0 MB 9.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 21.1/44.0 MB 9.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 21.5/44.0 MB 9.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 22.0/44.0 MB 9.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 22.5/44.0 MB 9.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 22.9/44.0 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 23.4/44.0 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 23.7/44.0 MB 9.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 24.1/44.0 MB 9.2 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 24.6/44.0 MB 9.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 25.0/44.0 MB 9.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 25.4/44.0 MB 9.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 25.8/44.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 26.4/44.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 26.8/44.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 27.2/44.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 27.8/44.0 MB 9.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.4/44.0 MB 9.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 28.9/44.0 MB 9.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 29.4/44.0 MB 9.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 29.8/44.0 MB 9.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.2/44.0 MB 9.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.6/44.0 MB 9.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.0/44.0 MB 9.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.5/44.0 MB 9.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 31.9/44.0 MB 9.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.3/44.0 MB 9.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.6/44.0 MB 9.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.9/44.0 MB 9.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.3/44.0 MB 9.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.8/44.0 MB 9.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.3/44.0 MB 9.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.8/44.0 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 35.3/44.0 MB 9.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 35.9/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 36.3/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 36.7/44.0 MB 9.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.2/44.0 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 37.6/44.0 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.0/44.0 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.4/44.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 38.9/44.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.3/44.0 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 39.8/44.0 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.2/44.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.7/44.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.2/44.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.6/44.0 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.3/44.0 MB 9.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.7/44.0 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.1/44.0 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.5/44.0 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.0/44.0 MB 6.4 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.3.1 scipy-1.11.2 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SaveWiki\n",
    "\n",
    "#SaveWiki.downloadWikiCat('Liste_(Parteien)','partei')\n",
    "#SaveWiki.downloadWikiCat('Liste_von_Religionen_und_Weltanschauungen','religion')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Texten aufmachen und lesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs \n",
    "\n",
    "def readtext(dateiname):\n",
    "    text = ''\n",
    "    d = codecs.open(dateiname,'r','utf8')\n",
    "    for zeile in d:\n",
    "        text += str(zeile)\n",
    "    d.close()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eine Reihe der Religionen und Weltanschauungen der Welt lässt sich schwer systematisieren, da vielfältige Elemente ineinanderspielen und es unterschiedliche Auffassungen dazu gibt, was eine Religion oder eine Weltsicht ausmacht (mit diesem Thema beschäftigt sich unter anderem die Religionswissenscha\n"
     ]
    }
   ],
   "source": [
    "bsptext= readtext('religion/Liste_von_Religionen_und_Weltanschauungen.txt')\n",
    "print(bsptext[:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merkmalen des Textes auswählen\n",
    "\n",
    "*1.stopwords ausschließen*\n",
    "\n",
    "*Zeichen ausschließen*\n",
    "\n",
    "*closed class words ausschließen*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aber', 'alle', 'allem', 'allen', 'aller', 'alles', 'als', 'also', 'am', 'an', 'ander', 'andere', 'anderem', 'anderen', 'anderer', 'anderes', 'anderm', 'andern', 'anderr', 'anders', 'auch', 'auf', 'aus', 'bei', 'bin', 'bis', 'bist', 'da', 'damit', 'dann', 'der', 'den', 'des', 'dem', 'die', 'das', 'dass', 'daß', 'derselbe', 'derselben', 'denselben', 'desselben', 'demselben', 'dieselbe', 'dieselben', 'dasselbe', 'dazu', 'dein', 'deine', 'deinem', 'deinen', 'deiner', 'deines', 'denn', 'derer', 'dessen', 'dich', 'dir', 'du', 'dies', 'diese', 'diesem', 'diesen', 'dieser', 'dieses', 'doch', 'dort', 'durch', 'ein', 'eine', 'einem', 'einen', 'einer', 'eines', 'einig', 'einige', 'einigem', 'einigen', 'einiger', 'einiges', 'einmal', 'er', 'ihn', 'ihm', 'es', 'etwas', 'euer', 'eure', 'eurem', 'euren', 'eurer', 'eures', 'für', 'gegen', 'gewesen', 'hab', 'habe', 'haben', 'hat', 'hatte', 'hatten', 'hier', 'hin', 'hinter', 'ich', 'mich', 'mir', 'ihr', 'ihre', 'ihrem', 'ihren', 'ihrer', 'ihres', 'euch', 'im', 'in', 'indem', 'ins', 'ist', 'jede', 'jedem', 'jeden', 'jeder', 'jedes', 'jene', 'jenem', 'jenen', 'jener', 'jenes', 'jetzt', 'kann', 'kein', 'keine', 'keinem', 'keinen', 'keiner', 'keines', 'können', 'könnte', 'machen', 'man', 'manche', 'manchem', 'manchen', 'mancher', 'manches', 'mein', 'meine', 'meinem', 'meinen', 'meiner', 'meines', 'mit', 'muss', 'musste', 'nach', 'nicht', 'nichts', 'noch', 'nun', 'nur', 'ob', 'oder', 'ohne', 'sehr', 'sein', 'seine', 'seinem', 'seinen', 'seiner', 'seines', 'selbst', 'sich', 'sie', 'ihnen', 'sind', 'so', 'solche', 'solchem', 'solchen', 'solcher', 'solches', 'soll', 'sollte', 'sondern', 'sonst', 'über', 'um', 'und', 'uns', 'unsere', 'unserem', 'unseren', 'unser', 'unseres', 'unter', 'viel', 'vom', 'von', 'vor', 'während', 'war', 'waren', 'warst', 'was', 'weg', 'weil', 'weiter', 'welche', 'welchem', 'welchen', 'welcher', 'welches', 'wenn', 'werde', 'werden', 'wie', 'wieder', 'will', 'wir', 'wird', 'wirst', 'wo', 'wollen', 'wollte', 'würde', 'würden', 'zu', 'zum', 'zur', 'zwar', 'zwischen']\n"
     ]
    }
   ],
   "source": [
    "#1:\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('german')\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from HanTa import HanoverTagger as ht\n",
    "from collections import Counter\n",
    "\n",
    "tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "\n",
    "def closed_class(pos):\n",
    "    if pos[0] == '$':\n",
    "        return True\n",
    "    elif pos in [\"APPR\", \"APPRART\", \"APPO\", \"APZR\", \"ART\", \"KOUI\", \"KOUS\", \"KON\", \"KOKOM\", \"PDS\", \"PDAT\", \"PIS\", \"PIAT\", \"PIDAT\", \"PPER\", \"PPOSS\", \"PPOSAT\", \"PRELS\", \"PRELAT\", \"PRF\", \"PWS\", \"PWAT\", \"PWAV\", \"PAV\", \"PTKZU\", \"PTKNEG\", \"VAFIN\", \"VAIMP\", \"VAINF\", \"VAPP\", \"VMFIN\", \"VMINF\", \"VMPP\"]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def features_from_text(text):\n",
    "    wordcounts = Counter()\n",
    "    tlen = 0\n",
    "    \n",
    "    satzliste =  nltk.sent_tokenize(text,language='german')\n",
    "    for satz in satzliste:\n",
    "        tokens =  nltk.word_tokenize(satz,language='german')\n",
    "        tokens = [lemma for (word,lemma,pos) in tagger.tag_sent(tokens) if not closed_class(pos)]\n",
    "        tokens = [t for t in tokens if t.lower() not in stopwords]\n",
    "        tokens = [t for t in tokens if re.search('^\\w+$',t)]\n",
    "        tlen += len(tokens)\n",
    "        wordcounts.update(tokens)\n",
    "\n",
    "    return {w:wordcounts[w]/tlen for w in wordcounts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_from_text(bsptext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir versuchen aus jede Klasse 50 Dokumente zu lesen, die nicht extrem kurz oder lang sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def read_data(directories):\n",
    "    docs = []\n",
    "    for directory in directories:\n",
    "        dirsize = 0\n",
    "        for file in glob.glob('data_intocode/'+directory+\"/*.txt\"):\n",
    "            text = readtext(file)\n",
    "            if len(text) > 500 and len(text) < 10000:\n",
    "                docs.append((features_from_text(text),directory))\n",
    "                dirsize += 1\n",
    "            if dirsize >= 50:\n",
    "                break\n",
    "    return docs\n",
    "\n",
    "data=read_data(['religion','partei'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Enkoimesis': 0.0055248618784530384,\n",
       "  'altgriechisch': 0.0055248618784530384,\n",
       "  'Ἐγκοίμησις': 0.0055248618784530384,\n",
       "  'Inkubation': 0.011049723756906077,\n",
       "  'lateinisch': 0.0055248618784530384,\n",
       "  'Incubatio': 0.0055248618784530384,\n",
       "  'Tempelschlaf': 0.016574585635359115,\n",
       "  'bezeichnen': 0.0055248618784530384,\n",
       "  'Antike': 0.0055248618784530384,\n",
       "  'belegt': 0.0055248618784530384,\n",
       "  'Praxis': 0.011049723756906077,\n",
       "  'Trauminkubation': 0.0055248618784530384,\n",
       "  'Kranke': 0.0055248618784530384,\n",
       "  'Heiligtum': 0.022099447513812154,\n",
       "  'Gott': 0.011049723756906077,\n",
       "  'Heros': 0.0055248618784530384,\n",
       "  'aufsuchen': 0.0055248618784530384,\n",
       "  'manchmal': 0.0055248618784530384,\n",
       "  'Verbindung': 0.0055248618784530384,\n",
       "  'entsprechend': 0.0055248618784530384,\n",
       "  'Ritual': 0.0055248618784530384,\n",
       "  'mehr': 0.0055248618784530384,\n",
       "  'minder': 0.0055248618784530384,\n",
       "  'aufwändig': 0.0055248618784530384,\n",
       "  'Vorbereitung': 0.0055248618784530384,\n",
       "  'Bad': 0.0055248618784530384,\n",
       "  'Fast': 0.0055248618784530384,\n",
       "  'Diät': 0.0055248618784530384,\n",
       "  'Opfer': 0.0055248618784530384,\n",
       "  'Gebet': 0.0055248618784530384,\n",
       "  'darauf': 0.0055248618784530384,\n",
       "  'hoffen': 0.0055248618784530384,\n",
       "  'Traumschlaf': 0.0055248618784530384,\n",
       "  'Hinweis': 0.0055248618784530384,\n",
       "  'wirksam': 0.0055248618784530384,\n",
       "  'Therapie': 0.0055248618784530384,\n",
       "  'Krankheit': 0.0055248618784530384,\n",
       "  'erhalten': 0.0055248618784530384,\n",
       "  'allgemein': 0.0055248618784530384,\n",
       "  'Sinn': 0.0055248618784530384,\n",
       "  'handeln': 0.0055248618784530384,\n",
       "  'Bezeichnung': 0.0055248618784530384,\n",
       "  'Schlaf': 0.0055248618784530384,\n",
       "  'Tempel': 0.0055248618784530384,\n",
       "  'orakelsuchend': 0.0055248618784530384,\n",
       "  'Antwort': 0.0055248618784530384,\n",
       "  'Frage': 0.0055248618784530384,\n",
       "  'erhoffen': 0.0055248618784530384,\n",
       "  'Inhalt': 0.0055248618784530384,\n",
       "  'Traum': 0.0055248618784530384,\n",
       "  'normalerweise': 0.0055248618784530384,\n",
       "  'unmittelbar': 0.0055248618784530384,\n",
       "  'verständlich': 0.0055248618784530384,\n",
       "  'bedürfen': 0.0055248618784530384,\n",
       "  'Deutung': 0.0055248618784530384,\n",
       "  'Priester': 0.0055248618784530384,\n",
       "  'jeweilig': 0.0055248618784530384,\n",
       "  'Jahrhundert': 0.0055248618784530384,\n",
       "  'häufig': 0.0055248618784530384,\n",
       "  'griechisch': 0.011049723756906077,\n",
       "  'Heilgott': 0.0055248618784530384,\n",
       "  'Asklepio': 0.0055248618784530384,\n",
       "  'einzig': 0.0055248618784530384,\n",
       "  'Sleeping': 0.0055248618784530384,\n",
       "  'Lady': 0.0055248618784530384,\n",
       "  'figürlich': 0.0055248618784530384,\n",
       "  'Plastik': 0.0055248618784530384,\n",
       "  'Malta': 0.0055248618784530384,\n",
       "  'Darstellung': 0.0055248618784530384,\n",
       "  'deuten': 0.0055248618784530384,\n",
       "  'Heiligtümer': 0.011049723756906077,\n",
       "  'Enkoimesi': 0.0055248618784530384,\n",
       "  'belegen': 0.0055248618784530384,\n",
       "  'christlich': 0.0055248618784530384,\n",
       "  'Zeit': 0.0055248618784530384,\n",
       "  'Ägypten': 0.0055248618784530384,\n",
       "  'Heilschlaf': 0.0055248618784530384,\n",
       "  'schriftlich': 0.0055248618784530384,\n",
       "  'Quelle': 0.0055248618784530384,\n",
       "  'Anbau': 0.0055248618784530384,\n",
       "  'Märtyrerkirche': 0.0055248618784530384,\n",
       "  'Menasstadt': 0.0055248618784530384,\n",
       "  'finden': 0.0055248618784530384,\n",
       "  'islamisch': 0.0055248618784530384,\n",
       "  'Gestalt': 0.0055248618784530384,\n",
       "  'Istichāra': 0.0055248618784530384,\n",
       "  'Istiḫāra': 0.0055248618784530384,\n",
       "  'hierbei': 0.0055248618784530384,\n",
       "  'sprechen': 0.0055248618784530384,\n",
       "  'Muslim': 0.0055248618784530384,\n",
       "  'bestimmt': 0.0055248618784530384,\n",
       "  'Bittgebet': 0.0055248618784530384,\n",
       "  'betreffend': 0.011049723756906077,\n",
       "  'schlafen': 0.0055248618784530384,\n",
       "  'legen': 0.0055248618784530384,\n",
       "  'Ritus': 0.0055248618784530384,\n",
       "  'knüpfen': 0.0055248618784530384,\n",
       "  'Erwartung': 0.0055248618784530384,\n",
       "  'Person': 0.0055248618784530384,\n",
       "  'heilvoll': 0.0055248618784530384,\n",
       "  'Wirkung': 0.0055248618784530384,\n",
       "  'Literatur': 0.0055248618784530384,\n",
       "  'Gustav': 0.0055248618784530384,\n",
       "  'Türk': 0.0055248618784530384,\n",
       "  'Oneiro': 0.0055248618784530384,\n",
       "  'Wilhelm': 0.0055248618784530384,\n",
       "  'Heinrich': 0.0055248618784530384,\n",
       "  'Roscher': 0.0055248618784530384,\n",
       "  'Hrsg': 0.011049723756906077,\n",
       "  'ausführlich': 0.0055248618784530384,\n",
       "  'Lexikon': 0.0055248618784530384,\n",
       "  'römisch': 0.0055248618784530384,\n",
       "  'Mythologie': 0.0055248618784530384,\n",
       "  'Band': 0.011049723756906077,\n",
       "  'Leipzig': 0.0055248618784530384,\n",
       "  '1902': 0.0055248618784530384,\n",
       "  'Sp': 0.0055248618784530384,\n",
       "  'Digitalisat': 0.0055248618784530384,\n",
       "  'Meier': 0.0055248618784530384,\n",
       "  'Ancient': 0.0055248618784530384,\n",
       "  'Incubation': 0.011049723756906077,\n",
       "  'And': 0.0055248618784530384,\n",
       "  'Modern': 0.0055248618784530384,\n",
       "  'Psychotherapy': 0.0055248618784530384,\n",
       "  'Evanston': 0.0055248618784530384,\n",
       "  'Il': 0.0055248618784530384,\n",
       "  '1967': 0.0055248618784530384,\n",
       "  'Helmut': 0.0055248618784530384,\n",
       "  'Siefert': 0.0055248618784530384,\n",
       "  'Werner': 0.0055248618784530384,\n",
       "  'Gerabek': 0.0055248618784530384,\n",
       "  'Bernhard': 0.0055248618784530384,\n",
       "  'Haag': 0.0055248618784530384,\n",
       "  'Gundolf': 0.0055248618784530384,\n",
       "  'Keil': 0.0055248618784530384,\n",
       "  'Wolfgang': 0.0055248618784530384,\n",
       "  'Wegner': 0.0055248618784530384,\n",
       "  'Enzyklopädie': 0.0055248618784530384,\n",
       "  'Medizingeschichte': 0.0055248618784530384,\n",
       "  'De': 0.0055248618784530384,\n",
       "  'Gruyter': 0.0055248618784530384,\n",
       "  'Berlin': 0.0055248618784530384,\n",
       "  'New': 0.0055248618784530384,\n",
       "  'York': 0.0055248618784530384,\n",
       "  '2005': 0.0055248618784530384,\n",
       "  'Isbn': 0.0055248618784530384,\n",
       "  '1381': 0.0055248618784530384,\n",
       "  'Gil': 0.0055248618784530384,\n",
       "  'Renberg': 0.0055248618784530384,\n",
       "  'Wher': 0.0055248618784530384,\n",
       "  'Dream': 0.0055248618784530384,\n",
       "  'May': 0.0055248618784530384,\n",
       "  'Come': 0.0055248618784530384,\n",
       "  'Sanctuaries': 0.0055248618784530384,\n",
       "  'The': 0.011049723756906077,\n",
       "  'World': 0.011049723756906077,\n",
       "  'Religion': 0.0055248618784530384,\n",
       "  '184': 0.0055248618784530384,\n",
       "  '2': 0.0055248618784530384,\n",
       "  'Teilband': 0.0055248618784530384,\n",
       "  'Brill': 0.0055248618784530384,\n",
       "  'Leiden': 0.0055248618784530384,\n",
       "  '2017': 0.0055248618784530384,\n",
       "  'isbn': 0.0055248618784530384,\n",
       "  'Einzelnachweise': 0.0055248618784530384},\n",
       " 'religion')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir mischen die Daten und teilen in Test- und Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(data)\n",
    "train_data = data[:40]\n",
    "test_data = data[40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir schauen uns jetzt mal ein Dokument an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben jetzt für jedes Dokument einene Merkmalsvektor. Man merke: der Vektor ist eigentlich so lang wie die Anzahl der unterschiedlichen Wörter in der ganzen Sammlung. Alle Wörter, die nicht erwähnt werden haben den Wert 0. \n",
    "\n",
    "Wörter, die nur in ein oder zwei Dokumementen vorkommen sind, für die Klassifikation nicht besonders nützlich. \n",
    "Wir nutzen nachher nur die Wörter, die in mindestens 5 Dokumente vorkommen. Um das vorzubereiten, berechnen wir für alle Wörter die Dokumentfrequenz>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfreq = Counter()\n",
    "for (wfreq,c) in train_data:\n",
    "    docfreq.update(wfreq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docfreq\n",
    "\n",
    "Textvektor=[5,0,0,1,...,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation mit Scikit Learn\n",
    "\n",
    "Die Bibliothek Scikit Learn stellt verschiedene Klassifikationsmodelle zur Verfügung. Wir müssen jetzt richtige Merkmalsvektoren aufbauen, bei denen die Position die Bedeutung einer Zahl bestimmt. Dazu machen wir erst eine feste Liste mit allen Wörtern. Wörter, die zu selten sind lassen wir weg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "\n",
    "\n",
    "allfeatures = [w for w in docfreq if docfreq[w] > 4]\n",
    "\n",
    "def make_feat_vec(featmap,featlist):\n",
    "    vec = []\n",
    "    for f in featlist:\n",
    "        vec.append(featmap.get(f,0.0))\n",
    "    return vec\n",
    "\n",
    "train_vec =  [make_feat_vec(feats,allfeatures) for feats,cls in train_data]\n",
    "train_label = [cls for feats,cls in train_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir schauen uns mal einen Vektor an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vec[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.006920415224913495,\n",
       " 0.03460207612456748,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0034602076124567475,\n",
       " 0.006920415224913495,\n",
       " 0.0,\n",
       " 0.01384083044982699,\n",
       " 0.0034602076124567475,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0034602076124567475,\n",
       " 0.0,\n",
       " 0.006920415224913495,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.01384083044982699,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.01384083044982699,\n",
       " 0.0,\n",
       " 0.006920415224913495,\n",
       " 0.0,\n",
       " 0.0034602076124567475,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0034602076124567475,\n",
       " 0.0034602076124567475,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0034602076124567475,\n",
       " 0.0034602076124567475,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.010380622837370242,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.10726643598615918,\n",
       " 0.0034602076124567475,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0034602076124567475,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0034602076124567475,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.006920415224913495,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0034602076124567475,\n",
       " 0.0034602076124567475,\n",
       " 0.0034602076124567475,\n",
       " 0.006920415224913495,\n",
       " 0.03806228373702422,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.03460207612456748,\n",
       " 0.03460207612456748,\n",
       " 0.0,\n",
       " 0.0034602076124567475,\n",
       " 0.0,\n",
       " 0.020761245674740483,\n",
       " 0.0034602076124567475,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0034602076124567475,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.006920415224913495,\n",
       " 0.0]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'partei'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein einfaches, aber effektives Klassifikationsmodell, das meistens gute Ergebnisse liefert, ist die logistische Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1000000000.0, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1000000000.0, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1000000000.0, verbose=True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e9,verbose=True)\n",
    "logreg.fit(train_vec,train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können jetzt mit dem trainierten Classifier ein neues Dokument klassifizieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['partei'], dtype='<U8')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = make_feat_vec(test_data[17][0],allfeatures) \n",
    "logreg.predict([v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Richtig ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'partei'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[17][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oder direkt für alles Testdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec = [make_feat_vec(feats,allfeatures) for feats,cls in test_data]\n",
    "test_label = [cls for feats,cls in test_data]\n",
    "\n",
    "pred_label = list(logreg.predict(test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 Prozent korrekt\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(test_label)):\n",
    "    if test_label[i] == pred_label[i]:\n",
    "        correct+=1\n",
    "print(\"{0:.1f} Prozent korrekt\".format(100* float(correct)/len(test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f-Faktor\n",
    "Recall\n",
    "Precision\n",
    "Stearman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wo sind aber die Fehler aufgetreten? Un diese Frage zu beantworten, ist sogenannte eine _Konfusionsmatrix_ sehr hilfreich. NLTK hat eine Funktion zum erstellen eines Konfusionsmatrizen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         |     r |\n",
      "         |     e |\n",
      "         |  p  l |\n",
      "         |  a  i |\n",
      "         |  r  g |\n",
      "         |  t  i |\n",
      "         |  e  o |\n",
      "         |  i  n |\n",
      "---------+-------+\n",
      "  partei |<18> . |\n",
      "religion |  . <5>|\n",
      "---------+-------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = nltk.ConfusionMatrix(test_label, pred_label)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt verschiedene andere Klassifikatorn, die wie nutzen können:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.0 Prozent korrekt\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(train_vec,train_label)\n",
    "pred_label = list(knn.predict(test_vec))\n",
    "correct = 0\n",
    "for i in range(len(test_label)):\n",
    "    if test_label[i] == pred_label[i]:\n",
    "        correct+=1\n",
    "print(\"{0:.1f} Prozent korrekt\".format(100* float(correct)/len(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.0 Prozent korrekt\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf.fit(train_vec,train_label)\n",
    "pred_label = list(rf.predict(test_vec))\n",
    "correct = 0\n",
    "for i in range(len(test_label)):\n",
    "    if test_label[i] == pred_label[i]:\n",
    "        correct+=1\n",
    "print(\"{0:.1f} Prozent korrekt\".format(100* float(correct)/len(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
