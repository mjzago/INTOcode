{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimentanalyse\n",
    "\n",
    "Sentimentanalyse, auch _Opinion Mining_ genannt, ist das herausfinden der Meinung, die in einem Text zu igendetwas geäußert wird.\n",
    "\n",
    "Es werden zwei Dimensionen, entlang denen Text klassifiziert werden können, unterschieden: \n",
    " * Objektiv vs. Subjektiv und \n",
    " * Negativ - Neutral - Positiv.\n",
    "\n",
    "Längere Texte können natürlich mehrere Meinungen zu den gleichen und zu verschiedenen Sachen enthalten. Im folgenden machen wir mal die vereinfachende Annahme, das Texte immer homogen sind. \n",
    "\n",
    "Unsere einfache Hypothese ist, dass es Wörter gibt, die eine stark positives oder negatives Sentiment verkörpern, und das es reicht diese Wörter zu finden, um einen Text zu klassifizieren. Diese Annahme ist natürlich nicht ganz korrekt. Eine positive ode negative Meinung hängt natürlich von mehr als nur von einzelnen Wörtern ab: insbesondere  Negation kann die Bedeutung eines Wortes grundlegend ändern. Einige ganz neue Verfahren (Stichwörter: ELMO und BERT) können auch mit der unterschiedliche Bedeutung von Wörtern in Abhängigkeit der umgebenden Wörter umgehen. Wir kommen aber schon ganz weit, wenn wir nur einzelne Wörter verwenden. Verfahren, die nur einzelne Wörter verwenden, ohne ihre Beziehungen zu berücksichtigen, nennt man übrigens _Bag of Word_-Verfahren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt nun zwei Möglichkeiten die Idee umzusetzen:\n",
    "1. Wir trainieren einen Classifier, der aus Beispieltexten lernt, wie viel jedes Wort zum positiven oder negativen Sentiment beiträgt. Der Vorteil dieser Methode ist, dass wie genaue gewichte für eine spezifische Domäne oder Textart lernen können. Der Nachteil ist, dass wir Texte brauchen, die händisch beuurteilt wurden.\n",
    "2. Wir nutzen allgemeine Listen mit positiven und negativen Wörtern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Für die Sentimentanalyse brauchen wir in Grunde genommen nur Listen mit positiven und negativen Wörtern und eine Funktion, die zählt wie viele positive und negative Wörter es in einem Text gibt. Es gibt aber auch Tools, die das alles ganz unkomplziert für uns erledigen können. Für die Sentimentanalyse können wir die Bibiothek _TextBlob_ nutzen.\n",
    "\n",
    "Das ist jetzt die dritte Bibliothek für NLP. Was sind die Unterschiede?\n",
    "\n",
    "* NLTK: Eine Sammlung mit sehr vielen Algorithmen, meistens sprachunabhängig oder für viele Sprachen geeignet. Oft auch viele unterschiedliche Algorithmen für dieselbe Aufgabe. Ein Eldorado für Experte, die experimentieren und selber neue Anwendungen entwickeln wollen.\n",
    "* TextBlob: eine Auswahl von Algorithmen aus NLTK, die zusammen eine Standard-Analyse eines Textes für einige wenige Sprachen ausführen können. Wenig Vorwissn erforderlich, einfach einzusetzen, aber ohne Möglichkeiten, etwas anzupassen.\n",
    "* Spacy: von der Idee und Funktionalität sehr ähnlich zu TextBlob, etwas umfangreicher und vorallem mit eigener sehr performante Implementierung.\n",
    "\n",
    "Weder NLTK noch Spacy enthalten eine fertig eingebaute Sentimentanalyse für Deutsche Texte. TextBlob bietet diese Funktionalität aber. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textanalyse mit TextBlob\n",
    "\n",
    "Zunächst installieren wir die Deutsche Version von TextBlob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob-de==0.4.3 in c:\\users\\mjzag\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: textblob>=0.9.0 in c:\\users\\mjzag\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textblob-de==0.4.3) (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\mjzag\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textblob>=0.9.0->textblob-de==0.4.3) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\mjzag\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob>=0.9.0->textblob-de==0.4.3) (8.1.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\mjzag\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob>=0.9.0->textblob-de==0.4.3) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mjzag\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob>=0.9.0->textblob-de==0.4.3) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mjzag\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob>=0.9.0->textblob-de==0.4.3) (4.65.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mjzag\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk>=3.1->textblob>=0.9.0->textblob-de==0.4.3) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U textblob-de==0.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\mjzag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mjzag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mjzag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mjzag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\mjzag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\mjzag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir nehmen mal drei kurze Texte, und schauen, was TextBlob damit so macht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Text laden wir jetzt in ein TextBlob-Objekt. Dabei wird dieser Text vollständig analysiert. Anschließend können wir die Analzsen aus dem Objekt auslesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textblob\n",
    "from textblob_de import TextBlobDE\n",
    "\n",
    "\n",
    "blob1 = TextBlobDE(text1)\n",
    "blob1.sentiment.polarity \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob2 = TextBlobDE(text2)\n",
    "blob2.sentiment.polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m blob3 \u001b[39m=\u001b[39m TextBlobDE(text3)\n\u001b[0;32m      2\u001b[0m blob3\u001b[39m.\u001b[39msentiment\u001b[39m.\u001b[39mpolarity \n",
      "\u001b[1;31mNameError\u001b[0m: name 'text3' is not defined"
     ]
    }
   ],
   "source": [
    "blob3 = TextBlobDE(text3)\n",
    "blob3.sentiment.polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Wer braucht diese Bücher mit ihren Plattheiten?\"),\n",
       " Sentence(\"Eine Zumutung für Leser mit einem gewissen Anspruch.\")]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Wer', 'braucht', 'diese', 'Bücher', 'mit', 'ihren', 'Plattheiten', '?', 'Eine', 'Zumutung', 'für', 'Leser', 'mit', 'einem', 'gewissen', 'Anspruch', '.'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['wer', 'brauchen', 'dies', 'Bücher', 'mit', 'ihren', 'Plattheiten', 'Ein', 'Zumutung', 'für', 'Leser', 'mit', 'ein', 'gewiss', 'Anspruch'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wer', 'WP'),\n",
       " ('braucht', 'VB'),\n",
       " ('diese', 'DT'),\n",
       " ('Bücher', 'NN'),\n",
       " ('mit', 'IN'),\n",
       " ('ihren', 'PRP$'),\n",
       " ('Plattheiten', 'NN'),\n",
       " ('Eine', 'DT'),\n",
       " ('Zumutung', 'NN'),\n",
       " ('für', 'IN'),\n",
       " ('Leser', 'NN'),\n",
       " ('mit', 'IN'),\n",
       " ('einem', 'DT'),\n",
       " ('gewissen', 'JJ'),\n",
       " ('Anspruch', 'NN')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'wer': 1,\n",
       "             'braucht': 1,\n",
       "             'diese': 1,\n",
       "             'bücher': 1,\n",
       "             'mit': 2,\n",
       "             'ihren': 1,\n",
       "             'plattheiten': 1,\n",
       "             'eine': 1,\n",
       "             'zumutung': 1,\n",
       "             'für': 1,\n",
       "             'leser': 1,\n",
       "             'einem': 1,\n",
       "             'gewissen': 1,\n",
       "             'anspruch': 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "text2 =  'scheißes'\n",
    "blob2=TextBlobDE(text2)\n",
    "s=blob2.polarity\n",
    "if s>=0.5:\n",
    "    print('sehr positve')\n",
    "elif 0<=s<0.5:\n",
    "    print('positive')\n",
    "else:\n",
    "    print('negative') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from textblob_de import PatternParser\n",
    "#blob = TextBlobDE(text, parser=PatternParser(pprint=True, lemmata=True))\n",
    "#blob.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "fhand=open('motogpositive.txt')\n",
    "i=0\n",
    "text=fhand.read()\n",
    "x=text.find('Farbe:')\n",
    "print(x)\n",
    "\n",
    "for line in fhand:\n",
    "    line=line.rstrip()\n",
    "    if line.startswith('Farbe:'):\n",
    "        name='motogpositive'+str(i)\n",
    "        #print(name)\n",
    "        i=i+1\n",
    "    print(x)\n",
    "#         fout=codecs.open(name,'w','utf8')\n",
    "#         print()\n",
    "        \n",
    "# i=0\n",
    "# for file in files:\n",
    "#     try:\n",
    "#         fhand=codecs.open(file,'r','cp1252')\n",
    "#         text=fhand.read()\n",
    "#         #fname=file[6:-3]+'utf.txt'\n",
    "#         i=i+1\n",
    "#         #fname=text+i\n",
    "#         fout=codecs.open(test, 'w', 'utf8')\n",
    "#         print(text, file=fout)\n",
    "#         fhand.close()\n",
    "#         fout.close()\n",
    "#     except:\n",
    "#         try:\n",
    "#             fhand=codecs.open(file,'r','utf8')\n",
    "#             text=fhand.read()\n",
    "#             #fname=file[6:-3]+'utf.txt'\n",
    "#             fout=codecs.open(test2, 'w', 'utf8')\n",
    "#             print(text, file=fout)\n",
    "#             fhand.close()\n",
    "#             fout.close()\n",
    "#         except:\n",
    "#             print(file)\n",
    "#             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateipos1=codesc.open('pos/1.txt','r','utf8')\n",
    "textpos1=dateipos1.read()\n",
    "blob1 = TextBlobDE(textpos1)\n",
    "print(blob.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateipos1=codesc.open('pos/1.txt','r','utf8')\n",
    "textpos1=dateipos1.read()\n",
    "blob1 = TextBlobDE(textpos1)\n",
    "print(blob.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "polarity=[]\n",
    "motog=codecs.open('motog.txt','r','utf8')\n",
    "for line in motog:\n",
    "    blob = TextBlobDE(line)\n",
    "    polarity.append(blob.sentiment.polarity)\n",
    "\n",
    "\n",
    "np=0\n",
    "for p in polarity:\n",
    "    if p <0.6:\n",
    "        np=np+1\n",
    "    else: continue \n",
    "        \n",
    "print(np,'von', len(polarity),'da heißt',(np*100)/len(polarity),'Prozent Korrekt Auswertung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line='Abbau\tAbbau\tNN\t1,0000\t0,0000\t0,0000'\n",
    "w, l, pos, wpos, wneg, wneu = line.split('\\t')\n",
    "print(w,l,pos,wpos,wn,wneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-24e80d23b5d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m      \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m      \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m      \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwneg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwneu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 6)"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "datei=codecs.open('GermanPolarityProb.tsv','r','utf16')\n",
    "i=0\n",
    "for line in datei:\n",
    "     print(i)\n",
    "     i+=1\n",
    "     w, l, pos, wpos, wneg, wneu = line.split('\\t')\n",
    "    \n",
    "\n",
    "text='Wer braucht diese Bücher mit ihren Plattheiten? Eine Zumutung für Leser mit einem gewissen Anspruch.'\n",
    "for l in text:\n",
    "     lex[l]=(wpos,wn,wneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xfc in position 100: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-2b3f5d78f0ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatei\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\r71-dn9-u1\\Anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;31m# keep undecoded input until the next call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xfc in position 100: invalid start byte"
     ]
    }
   ],
   "source": [
    "datei.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method WordList.lemmatize of WordList(['Ich', 'bin', ',', 'aha', '.'])>\n"
     ]
    }
   ],
   "source": [
    "text='Ich bin, aha.'\n",
    "\n",
    "bl=TextBlobDE(text)\n",
    "print(bl.tokens.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 =  'Jetzt muss ich mal meinen ganzen Frust mit Emma rauslassen. Ich habe mir bei Emma ein Bett, eine Matratze und ein Kopfkissen (schon länger her) bestellt. Das Bett kam nach drei Tagen - wie angekündigt - an. Es war sehr einfach im Aufbau, sieht super aus, ist stabil und gemütlich. Die gleichzeitig bestellte Matratze habe ich über Emma bis heute nicht erhalten, obwohl sie zeitlich zusammen mit dem Bett kommen sollte. Per E-Mail oder Direktnachricht bei Facebook (wurde ich in den Kommentaren von Emma zu aufgefordert) habe ich bis heute keine Rückmeldung. Dementsprechend auch keine Rückerstattung. Nun bestellte ich dieselbe Matratze über Amazon. Die Lieferung klappte aufeinmal innerhalb von vier Tagen. Das Paket war aber dermaßen schlecht verpackt, dass alles total kaputt war. Die Matratze hat Risse und geht dank des unkomplizierten Rücksendeprozesses - über Amazon - zurück. Es wird aber lediglich angeboten, die schwere Matratze selber zu DHL zu bringen. Außerdem bekomme ich sie garnicht mehr in das Paket rein, da es dermaßen beschädigt war. Die Matratze wäre aber sowieso viel zu weich gewesen. Die Härten sind hier ganz anders als bei anderen Anbietern. Qualitativ machte sie sich keinen guten Eindruck. Nun zum letzten bestellten Artikel, mein Kissen über Emma. Das Kissen habe ich bereits vor zwei Jahren bestellt. Zugestellt wurde es sechs Monate nach der Bestellung. Katastrophe'\n",
    "\n",
    "\n",
    "text2 = 'Grundsätzlich gute Matratze und Bestellung sowie Lieferung hat über Amazon gut geklappt. Allerdings war die Matratze mir viel zu hart und ich wollte sie wie auch unter Amazon beschrieben innerhalb der 100 Tage zurückgeben. Hier aufpassen: Die Matratze kommt vakuumiert in einem Karton per Postpaket. Nach dem Auspacken nimmt sie ihre vielfache Größe an und ist unmöglich wieder zu komprimieren um in ein Paket zu passen. Bei einer Retoure über Amazon muss man die Ware aber wieder per Paket zurücksenden! Was ja nicht mehr geht! Bei der Hotline von Emma sagten die nur \"Wir würden gerne helfen aber wenn über Amazon gekauft muss man sich dorthin wenden\". Also ist man trotz groß umworbener 100 Tage Testphase ziemlich alleine gelassen! Also Vorsicht sonst hat man bei Rückgabe ziemlichen Ärger und Rennerei oder hat teures Lehrgeld bezahlt!'\n",
    "\n",
    "text3 = 'Hab die Matratze bestellt In medium ( ist leider viel zu hart ) Hab mich informiert im Internet und dort gesehen das Emma Matratzen anbietet in so einen Fall einen toppen kostenlos rauszusenden um zu testen ob es so dann passt für mich mit der Härte der Matratze Amazon bietet komischerweise nur die Rücksendung an obwohl im Internet was anderes steht Emma sagt sie können mir nicht helfen weil ich die Matratze über Amazon bestellt habe Amazon ihr enttäuscht mich hier gewaltig 3 mal mit Emma und 3 mal mit Amazon tel Keine Lösung also zurück schicken und direkt bei Emma bestellen ( die waren auch sehr unfreundlich am.tel )Jeder schiebt dad Problem auf den anderen. Danke für nichts'\n",
    "\n",
    "text4= 'Ich schlafe jetzt seit Anfang 2021 auf der Matratze und hatte immer die Hoffnung, dass sie irgendwann mal weicher wird. Aber sie ist immernoch hart wie ein Betonblock. Ich hatte extra medium gewählt. Ich bin 1,89m groß und ca.98 kg schwer. Und trotzdem schlafen mir auf der Matratze die Gliedmaßen ein. Ich hab durch die Matratze Rücken-und Nackenprobleme bekommen. Jetzt fliegt sie dahin, wo sie hingehört: Auf die Müllkippe. Es ärgert mich immer noch, dass ich mich auf die Bewertungen verlassen habe.'\n",
    "\n",
    "text5= 'Nachdem wir sehr viele positive Rezensionen der Emma One Matratze gelesen und uns ausgiebig informiert hatten, entschieden wir uns für die Emma One. Leider kamen wir beide überhaupt nicht mit der Matratze zurecht: wir gaben der Matratze 2 Wochen, da die Eingewöhnung ja manchmal etwas holprig sein kann. Besonders ich, aber auch mein Freund wachten täglich mit Kopfschmerzen und Verspannungen eines solch hohen und unangenehmen Maßes auf, dass wir uns entschlossen, die Matratzen zurückzugeben. Besonders ich konnte keine Nacht länger auf der Matratze schlafen.Dies kann ja durchaus passieren, Menschen und ihre Schlafbedürfnisse sind bekanntermaßen verschieden. Nun begann jedoch die eigentliche Odyssee mit Emma One. Das Werbeversprechen des 100 Tage Probeschlafens von Emma One wird offensichtlich mit Füßen getreten. Ich versuche nun seit Ende November, die Matratzen zurückzugeben. Da ich nicht einfach mit 2 Matratzen zur Post spazieren kann, muss Emma One sie abholen. Darauf warte ich nun nach unzähligen Telefonaten weiterhin vergeblich. Zum Glück ist der Amazon Kundenservice extrem hilfreich und freundlich- von Emma One bin ich jedenfalls maßlos enttäuscht. Es wird sich zeigen, ob die Matratze nun noch zurückgegeben werden kann, dieser Aufwand ist jedoch extrem unverhältnismäßig und steht in keinem Verhältnis zum Werbeversprechen. Das Fazit ist eindeutig: Keine Kaufempfehlung für Emma One!'\n",
    "\n",
    "text6 ='Die Investition hat sich gelohnt - habe die Matratze vor fast zwei Jahren gekauft und bin zufrieden. Anfangs hatten wir sie auf dem Boden verwendet und da fühlt sie sich sehr stabil und fast schon hart an. Für solche Verwendung würde ich empfehlen eine Version zu kaufen, die so weich wie möglich ist. Wenn man aber den richtigen Lattenrost drunter legt hat sie die perfekte Festigkeit! Dennoch: Wer normalerweise sehr weiche Matratzen verwendet sollte dementsprechend auch die Härte auswählen.Anfangs wenn man sie rausholt riecht sie noch sehr chemisch, also unbedingt Zeit einplanen zum auslüften lassen ;) Alles in allem bin ich schon sehr überzeugt von dieser Matratze. Würde ich wieder kaufen.'\n",
    "\n",
    "text7 = 'Die Matratzen kamen zeitnah und gut verpackt. Den Schoner und das Laken drüber und rauf auf den Lattenrost. Passt ganz genau, an die Härte muss man sich gewöhnen, aber die haben wir ja so bestellt. Sonst gibt es nicht viel zu sagen, man schläft gut und mehr will ich nicht. Ich würde sie wieder kaufen.'\n",
    "\n",
    "text8 = 'Matratze wurde 4Tage früher geliefert, kompakter Transport. Nachmittags erhalten, nach öffnen der Folie entfaltet sich die Matrtze, hab ihr mal 2/3 Stunden gegeben zum öffnen.. Der oft kritisierte Geruch kann ich erst mal nicht so bestätigen. Es riecht, aber sehr dezent. Ich lasse sie noch bis 22 uhr bei offenen Fenstern ausdünsten und entfalten. Werde sie doch schon in der ersten Nacht mal benutzen. . Bis jetzt soweit ok. 1 Nacht: Keine Gerüche wahrgenommen, besser geschlafen als auf der alten Matratze, das ist schon ein Fortschritt. Weiteres später Jetzt schon paar Nächte drauf verbracht, kann bis jettt nur positives berichten. Es gab ab Tag1 keine gerüchsauffälligkeitrn, und ich bin da sehr empfindlich. Bis jetzt war das liegen besser, mein schlechter Schlaf hat noch andere Gründe, kann die Emma One nix für. Werde weiter berichten'\n",
    "\n",
    "text9= 'Die Lieferung kam noch vor dem angegebenen Termin und war in einem Karton zusammengerollt verpackt. Nachmittags angekommen und abends schon drauf geschlafen. Sie hat sich relativ schnell entfaltet und hat keinen Eigengeruch. Diese Matratze hält wirklich, was sie verspricht. Ich bin begeistert von der Qualität. Sehr empfehlenswert.'\n",
    "\n",
    "text10 = 'Ich bin klein und die Matratze ist super für mich, passt sich an den Körper an. Ist auch nicht zu hart , wenn man so was mag :-) Danke und Grüße'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textblob\n",
    "from textblob_de import TextBlobDE\n",
    "\n",
    "\n",
    "blob1 = TextBlobDE(text1)\n",
    "blob1.sentiment.polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob2 = TextBlobDE(text2)\n",
    "blob2.sentiment.polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21333333333333332"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob3 = TextBlobDE(text4)\n",
    "blob4.sentiment.polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21333333333333332"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob4 = TextBlobDE(text4)\n",
    "blob4.sentiment.polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23749999999999996"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob5 = TextBlobDE(text5)\n",
    "blob5.sentiment.polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.075"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob6 = TextBlobDE(text6)\n",
    "blob6.sentiment.polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12666666666666665"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob7 = TextBlobDE(text7)\n",
    "blob7.sentiment.polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04615384615384616"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob8 = TextBlobDE(text8)\n",
    "blob8.sentiment.polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6166666666666667"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob9 = TextBlobDE(text9)\n",
    "blob9.sentiment.polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07500000000000001"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob10 = TextBlobDE(text10)\n",
    "blob10.sentiment.polarity "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
